import feedparser
import asyncio
import os
import json
import requests
import random
from bs4 import BeautifulSoup
import google.generativeai as genai
from telegram import Bot
from telegram.constants import ParseMode

# ุงูุฅุนุฏุงุฏุงุช ูู ูุชุบูุฑุงุช ุงูุจูุฆุฉ
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# ุฅุนุฏุงุฏ Gemini
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    # ุงุณุชุฎุฏุงู ููุฏูู Pro ููุฏุฑุงุช ุจุญุซ ูุชุญููู ุฃุนูู
    model = genai.GenerativeModel('gemini-1.5-pro')

# ูุตุงุฏุฑ ุงูุฃุฎุจุงุฑ
RSS_FEEDS = [
    "https://www.arabfinance.com/ar/rss/rssbycat/2",
    "https://www.arabfinance.com/ar/rss/rssbycat/3",
    "http://feeds.mubasher.info/ar/EGX/news",
]
MUBASHER_PULSE_URL = "https://www.mubasher.info/news/eg/pulse/stocks"

STOCK_KEYWORDS = [
    "ุณูู", "ุฃุณูู", "ุจูุฑุตุฉ", "ุงุฑุจุงุญ", "ุฃุฑุจุงุญ", "ุฎุณุงุฆุฑ", "ูุชุงุฆุฌ ุฃุนูุงู", 
    "ุฒูุงุฏุฉ ุฑุฃุณ ูุงู", "ุชูุฒูุน ููุจูู", "ุงุณุชุญูุงุฐ", "ุงูุฏูุงุฌ", "ุงูุชุชุงุจ", 
    "ุงูููุงุฆู ุงููุงููุฉ", "ูุฌูุณ ุฅุฏุงุฑุฉ", "ุฅูุตุงุญ", "ุชุฏุงูู", "ุงูุจูุฑุตุฉ ุงููุตุฑูุฉ",
    "EGX", "ููุจูู", "ุฌูุนูุฉ ุนููููุฉ", "ููุฆุฉ ุงูุฑูุงุจุฉ ุงููุงููุฉ", "ููุงุฒูุฉ"
]

SENT_NEWS_FILE = "sent_news.json"

async def analyze_news(title, description):
    prompt = f"""
    ุฃูุช ุฑุฆูุณ ูุณู ุงูุจุญูุซ ุงููุงููุฉ (Head of Equity Research) ูู ุจูู ุงุณุชุซูุงุฑ ูุฑููู. 
    ูููุชู ูู ุชูุฏูู "ุชูุฑูุฑ ุจุญุซู ูุตุบุฑ" (Mini Research Report) ุญูู ุงูุฎุจุฑ ุงูุชุงูู ูุชูุฏูู ูููุฉ ุญููููุฉ ูููุณุชุซูุฑูู ูู ุงูุจูุฑุตุฉ ุงููุตุฑูุฉ.
    
    ุงูุฎุจุฑ: {title}
    ุงูุชูุงุตูู: {description}
    
    ุงููุทููุจ ูู ุงูุชูุฑูุฑ ุงูุจุญุซู:
    1. **ุงูุณูุงู ุงูุงุณุชุฑุงุชูุฌู (Strategic Context)**: ุงุฑุจุท ุงูุฎุจุฑ ุจูุถุน ุงูุดุฑูุฉ ุงูุญุงูู ูู ุงูุณูู ุงููุตุฑู. ูู ูุฐุง ุงูุฎุจุฑ ูุนุฒุฒ ุญุตุชูุง ุงูุณูููุฉุ ูู ูุญู ูุดููุฉ ุณูููุฉุ
    2. **ุงูุชุญููู ุงููุงูู ุงูุนููู (Financial Deep Dive)**: ุญูู ุงูุฃุฑูุงู ุงููุฐููุฑุฉ. ุฅุฐุง ูุงูุช ุฃุฑุจุงุญุงูุ ูุงุฑููุง ุจุงูุชููุนุงุช ุฃู ุงูุฃุฏุงุก ุงูุชุงุฑูุฎู (ุจูุงุกู ุนูู ูุนุฑูุชู). ุฅุฐุง ูุงู ุงุณุชุญูุงุฐุงูุ ุญูู ูุถุงุนู ุงูุงุณุชุญูุงุฐ ุงููุญุชูู.
    3. **ุชุฃุซูุฑ ุงููููุฉ (Value Impact)**: ููู ุณูุคุซุฑ ูุฐุง ุงูุฎุจุฑ ุนูู "ุงููููุฉ ุงูุนุงุฏูุฉ" (Fair Value) ููุณูู ุนูู ุงููุฏู ุงููุชูุณุท ูุงูุจุนูุฏุ
    4. **ูุตูููุฉ ุงููุฎุงุทุฑ ูุงููุฑุต (Risk/Reward Matrix)**: ุงุฐูุฑ ุฃูู ูุฑุตุฉ ูุฎูููุง ุงูุฎุจุฑ ูุฃุฎุทุฑ ุฑูุณู ูุฏ ููุงุฌู ุงูุชูููุฐ.
    5. **ุงูุชูุตูุฉ ุงูุงุณุชุซูุงุฑูุฉ ุงูููุงุฆูุฉ (Investment Verdict)**: (ุดุฑุงุก / ุงุญุชูุงุธ / ุจูุน / ูุฑุงูุจุฉ) ูุน ุชุจุฑูุฑ ููุทูู ููู ุฌุฏุงู ูููุณุชุซูุฑ ุงูุฐูู.

    ุงุฌุนู ุงูุฃุณููุจ: ุงุญุชุฑุงููุ ุชุญููููุ ุจุนูุฏ ุนู ุงูุณุทุญูุฉุ ูุจุงููุบุฉ ุงูุนุฑุจูุฉ ุงููุตุญู ุงูููููุฉ. ุงุณุชุฎุฏู ุงูุฑููุฒ ุงูุชุนุจูุฑูุฉ (Emojis) ุจุดูู ุทููู ููุชูุธูู ููุท.
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"Gemini Error: {e}")
        return "ุนุฐุฑุงูุ ุชุนุฐุฑ ุฅุฌุฑุงุก ุงูุจุญุซ ุงููุงูู ุงููุชุนูู ุญุงููุงู."

def is_stock_related(title, description):
    content = (title + " " + description).lower()
    return any(keyword in content for keyword in STOCK_KEYWORDS)

def load_sent_news():
    if os.path.exists(SENT_NEWS_FILE):
        with open(SENT_NEWS_FILE, "r") as f:
            try: return json.load(f)
            except: return []
    return []

def save_sent_news(sent_news):
    with open(SENT_NEWS_FILE, "w") as f:
        json.dump(sent_news[-500:], f)

async def process_and_send(bot, news_id, title, description, link, sent_news):
    if news_id not in sent_news and is_stock_related(title, description):
        print(f"Researching: {title}")
        analysis = await analyze_news(title, description)
        
        # ุชูุณูู ุงูุฑุณุงูุฉ ูุชุธูุฑ ูุชูุฑูุฑ ุฑุณูู
        message = (
            f"๐ <b>ุชูุฑูุฑ ุจุญูุซ ุงูุจูุฑุตุฉ ุงููุตุฑูุฉ</b>\n"
            f"โโโโโโโโโโโโโโโ\n"
            f"๐ <b>ุงูุนููุงู:</b> {title}\n\n"
            f"๐ฐ <b>ููุฎุต ุงูุฎุจุฑ:</b>\n{description[:300]}...\n\n"
            f"๐ฌ <b>ุงูุชุญููู ุงูุจุญุซู ุงููุชุนูู:</b>\n{analysis}\n\n"
            f"๐ <a href='{link}'>ุงููุตุฏุฑ ุงูุฃุตูู</a>\n"
            f"โโโโโโโโโโโโโโโ\n"
            f"โ๏ธ <i>ูุฐุง ุงูุชุญููู ุชู ุจูุงุณุทุฉ ุฐูุงุก ุงุตุทูุงุนู ูุชุทูุฑ ูุฃุบุฑุงุถ ุงุณุชุฑุดุงุฏูุฉ ููุท.</i>"
        )
        
        try:
            await bot.send_message(chat_id=CHANNEL_ID, text=message, parse_mode=ParseMode.HTML)
            sent_news.append(news_id)
            return True
        except Exception as e:
            print(f"Error sending: {e}")
    return False

async def scrape_mubasher_pulse(bot, sent_news):
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        response = requests.get(MUBASHER_PULSE_URL, headers=headers, timeout=20)
        soup = BeautifulSoup(response.content, 'html.parser')
        articles = soup.find_all('a', class_='mi-article-list-item__title') or soup.find_all('a', href=True)
        count = 0
        for a in articles:
            title = a.get_text(strip=True)
            link = a['href']
            if not link.startswith('http'): link = "https://www.mubasher.info" + link
            news_id = link.split('/')[-1] or link
            if news_id not in sent_news and "/news/" in link and len(title) > 20:
                if await process_and_send(bot, news_id, title, "ุฎุจุฑ ุนุงุฌู ูู ูุจุถ ุงูุฃุณูู.", link, sent_news):
                    count += 1
                    await asyncio.sleep(5) # ุฒูุงุฏุฉ ุงูููุช ููุชุญููู ุงูุนููู
            if count >= 3: break # ุชูููู ุงูุนุฏุฏ ูุถูุงู ุฌูุฏุฉ ุงูุจุญุซ ููู ุฎุจุฑ
    except: pass

async def main():
    if not all([TELEGRAM_TOKEN, CHANNEL_ID, GEMINI_API_KEY]):
        print("Missing environment variables!")
        return
        
    bot = Bot(token=TELEGRAM_TOKEN)
    sent_news = load_sent_news()
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    for feed_url in RSS_FEEDS:
        try:
            response = requests.get(feed_url, headers=headers, timeout=20)
            feed = feedparser.parse(response.content)
            for entry in feed.entries[:5]:
                news_id = entry.get("guid", entry.link)
                await process_and_send(bot, news_id, entry.title, entry.get("description", ""), entry.link, sent_news)
        except: pass
    
    await scrape_mubasher_pulse(bot, sent_news)
    save_sent_news(sent_news)

if __name__ == "__main__":
    asyncio.run(main())
