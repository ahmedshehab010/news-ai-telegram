import feedparser
import asyncio
import os
import json
import requests
import random
from bs4 import BeautifulSoup
import google.generativeai as genai
from telegram import Bot
from telegram.constants import ParseMode

# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Ø¥Ø¹Ø¯Ø§Ø¯ Gemini
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-1.5-pro')

# Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
RSS_FEEDS = [
    "https://www.arabfinance.com/ar/rss/rssbycat/2",
    "https://www.arabfinance.com/ar/rss/rssbycat/3",
    "http://feeds.mubasher.info/ar/EGX/news",
]
MUBASHER_PULSE_URL = "https://www.mubasher.info/news/eg/pulse/stocks"

STOCK_KEYWORDS = [
    "Ø³Ù‡Ù…", "Ø£Ø³Ù‡Ù…", "Ø¨ÙˆØ±ØµØ©", "Ø§Ø±Ø¨Ø§Ø­", "Ø£Ø±Ø¨Ø§Ø­", "Ø®Ø³Ø§Ø¦Ø±", "Ù†ØªØ§Ø¦Ø¬ Ø£Ø¹Ù…Ø§Ù„", 
    "Ø²ÙŠØ§Ø¯Ø© Ø±Ø£Ø³ Ù…Ø§Ù„", "ØªÙˆØ²ÙŠØ¹ ÙƒÙˆØ¨ÙˆÙ†", "Ø§Ø³ØªØ­ÙˆØ§Ø°", "Ø§Ù†Ø¯Ù…Ø§Ø¬", "Ø§ÙƒØªØªØ§Ø¨", 
    "Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ø§Ù„ÙŠØ©", "Ù…Ø¬Ù„Ø³ Ø¥Ø¯Ø§Ø±Ø©", "Ø¥ÙØµØ§Ø­", "ØªØ¯Ø§ÙˆÙ„", "Ø§Ù„Ø¨ÙˆØ±ØµØ© Ø§Ù„Ù…ØµØ±ÙŠØ©",
    "EGX", "ÙƒÙˆØ¨ÙˆÙ†", "Ø¬Ù…Ø¹ÙŠØ© Ø¹Ù…ÙˆÙ…ÙŠØ©", "Ù‡ÙŠØ¦Ø© Ø§Ù„Ø±Ù‚Ø§Ø¨Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ©", "Ù…ÙˆØ§Ø²Ù†Ø©"
]

SENT_NEWS_FILE = "sent_news.json"

async def analyze_news(title, description):
    prompt = f"""
    Ø£Ù†Øª Ø±Ø¦ÙŠØ³ Ù‚Ø³Ù… Ø§Ù„Ø¨Ø­ÙˆØ« Ø§Ù„Ù…Ø§Ù„ÙŠØ© (Head of Equity Research) ÙÙŠ Ø¨Ù†Ùƒ Ø§Ø³ØªØ«Ù…Ø§Ø± Ù…Ø±Ù…ÙˆÙ‚. 
    Ù‚Ù… Ø¨ØªÙ‚Ø¯ÙŠÙ… ØªÙ‚Ø±ÙŠØ± Ø¨Ø­Ø«ÙŠ Ù…ØµØºØ± Ø­ÙˆÙ„ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„ØªØ§Ù„ÙŠ:
    Ø§Ù„Ø®Ø¨Ø±: {title}
    Ø§Ù„ØªÙØ§ØµÙŠÙ„: {description}
    
    Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø§Ø³ÙŠØŒ ØªØ£Ø«ÙŠØ± Ø§Ù„Ù‚ÙŠÙ…Ø©ØŒ Ù…ØµÙÙˆÙØ© Ø§Ù„Ù…Ø®Ø§Ø·Ø±ØŒ ÙˆØªÙˆØµÙŠØ© Ø§Ø³ØªØ«Ù…Ø§Ø±ÙŠØ© ÙˆØ§Ø¶Ø­Ø©.
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ ØªØ¹Ø°Ø± Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø§Ù„ÙŠ: {e}"

def is_stock_related(title, description):
    content = (title + " " + description).lower()
    return any(keyword in content for keyword in STOCK_KEYWORDS)

def load_sent_news():
    if os.path.exists(SENT_NEWS_FILE):
        with open(SENT_NEWS_FILE, "r") as f:
            try: return json.load(f)
            except: return []
    return []

def save_sent_news(sent_news):
    with open(SENT_NEWS_FILE, "w") as f:
        json.dump(sent_news[-500:], f)

async def process_and_send(bot, news_id, title, description, link, sent_news):
    if news_id not in sent_news and is_stock_related(title, description):
        print(f"Researching: {title}")
        analysis = await analyze_news(title, description)
        message = (
            f"ğŸ› <b>ØªÙ‚Ø±ÙŠØ± Ø¨Ø­ÙˆØ« Ø§Ù„Ø¨ÙˆØ±ØµØ© Ø§Ù„Ù…ØµØ±ÙŠØ©</b>\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ“Œ <b>Ø§Ù„Ø¹Ù†ÙˆØ§Ù†:</b> {title}\n\n"
            f"ğŸ”¬ <b>Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø«ÙŠ Ø§Ù„Ù…ØªØ¹Ù…Ù‚:</b>\n{analysis}\n\n"
            f"ğŸ”— <a href='{link}'>Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø£ØµÙ„ÙŠ</a>"
        )
        try:
            await bot.send_message(chat_id=CHANNEL_ID, text=message, parse_mode=ParseMode.HTML)
            sent_news.append(news_id)
            return True
        except Exception as e:
            print(f"Error sending: {e}")
    return False

async def main():
    if not all([TELEGRAM_TOKEN, CHANNEL_ID, GEMINI_API_KEY]):
        print("Missing environment variables!")
        return
        
    bot = Bot(token=TELEGRAM_TOKEN)
    sent_news = load_sent_news()
    
    # Ø±Ø³Ø§Ù„Ø© Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ (Ø³ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù ÙØ§Ø±ØºØ§Ù‹)
    if not sent_news:
        try:
            await bot.send_message(chat_id=CHANNEL_ID, text="ğŸš€ <b>ØªÙ… ØªÙØ¹ÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨Ø­ÙˆØ« Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!</b>\nØ§Ù„Ø¨ÙˆØª Ø§Ù„Ø¢Ù† ÙŠØ±Ø§Ù‚Ø¨ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¨ÙˆØ±ØµØ© Ø§Ù„Ù…ØµØ±ÙŠØ© 24/7.", parse_mode=ParseMode.HTML)
        except: pass

    headers = {'User-Agent': 'Mozilla/5.0'}
    
    # ÙØ­Øµ Ø§Ù„Ù€ RSS
    for feed_url in RSS_FEEDS:
        try:
            response = requests.get(feed_url, headers=headers, timeout=20)
            feed = feedparser.parse(response.content)
            for entry in feed.entries[:10]:
                news_id = entry.get("guid", entry.link)
                await process_and_send(bot, news_id, entry.title, entry.get("description", ""), entry.link, sent_news)
        except: pass
    
    # ÙØ­Øµ Ù†Ø¨Ø¶ Ø§Ù„Ø£Ø³Ù‡Ù… (ÙƒØ´Ø· Ù…Ø¨Ø§Ø´Ø±)
    try:
        response = requests.get(MUBASHER_PULSE_URL, headers=headers, timeout=20)
        soup = BeautifulSoup(response.content, 'html.parser')
        articles = soup.find_all('a', href=True)
        for a in articles:
            title = a.get_text(strip=True)
            link = a['href']
            if "/news/" in link and len(title) > 20:
                if not link.startswith('http'): link = "https://www.mubasher.info" + link
                news_id = link.split('/')[-1] or link
                await process_and_send(bot, news_id, title, "Ø®Ø¨Ø± Ø¹Ø§Ø¬Ù„ Ù…Ù† Ù†Ø¨Ø¶ Ø§Ù„Ø£Ø³Ù‡Ù….", link, sent_news)
    except: pass
    
    save_sent_news(sent_news)

if __name__ == "__main__":
    asyncio.run(main())
