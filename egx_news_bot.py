import feedparser
import asyncio
import os
import json
import requests
import re
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from google import genai
from telegram import Bot
from telegram.constants import ParseMode
import hashlib
from difflib import SequenceMatcher

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ---
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# --- Ù‚Ø§Ù…ÙˆØ³ Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø£Ø³Ù‡Ù… ---
TICKER_MAP = {
    "Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ Ø§Ù„Ø¯ÙˆÙ„ÙŠ": "COMI", "Ø§Ù„ØªØ¬Ø§Ø±ÙŠ Ø§Ù„Ø¯ÙˆÙ„ÙŠ": "COMI", "Ù…Ø¬Ù…ÙˆØ¹Ø© Ø·Ù„Ø¹Øª Ù…ØµØ·ÙÙ‰": "TMGH",
    "Ø·Ù„Ø¹Øª Ù…ØµØ·ÙÙ‰": "TMGH", "Ø§Ù„Ø³ÙˆÙŠØ¯ÙŠ Ø¥Ù„ÙŠÙƒØªØ±ÙŠÙƒ": "SWDY", "Ø§Ù„Ø³ÙˆÙŠØ¯ÙŠ": "SWDY",
    "Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¥ÙŠ Ø¥Ù Ø¬ÙŠ Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©": "HRHO", "Ø§ÙŠ Ø§Ù Ø¬ÙŠ": "HRHO", "Ø­Ø¯ÙŠØ¯ Ø¹Ø²": "ESRS",
    "Ø¹Ø² Ø§Ù„Ø¯Ø®ÙŠÙ„Ø©": "ESRS", "Ø£Ø¨Ùˆ Ù‚ÙŠØ± Ù„Ù„Ø£Ø³Ù…Ø¯Ø©": "ABUK", "ÙÙˆØ±ÙŠ": "FWRY",
    "Ù…ØµØ± Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø£Ø³Ù…Ø¯Ø© - Ù…ÙˆØ¨ÙƒÙˆ": "MFPC", "Ù…ÙˆØ¨ÙƒÙˆ": "MFPC", "Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ© Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø­Ø§ÙˆÙŠØ§Øª": "ALCN",
    "Ø§Ù„Ø´Ø±Ù‚ÙŠØ© - Ø§ÙŠØ³ØªØ±Ù† ÙƒÙˆÙ…Ø¨Ø§Ù†ÙŠ": "EAST", "Ø§ÙŠØ³ØªØ±Ù† ÙƒÙˆÙ…Ø¨Ø§Ù†ÙŠ": "EAST", "Ø¨Ø§Ù„Ù… Ù‡ÙŠÙ„Ø²": "PHDC",
    "Ø³ÙŠØ¯ÙŠ ÙƒØ±ÙŠØ± Ù„Ù„Ø¨ØªØ±ÙˆÙƒÙŠÙ…Ø§ÙˆÙŠØ§Øª": "SKPC", "Ø³ÙŠØ¯Ø¨Ùƒ": "SKPC", "Ø£ÙˆØ±Ø§Ø³ÙƒÙˆÙ… ÙƒÙˆÙ†Ø³ØªØ±Ø§ÙƒØ´ÙˆÙ†": "ORAS",
    "Ø¬ÙŠ Ø¨ÙŠ ÙƒÙˆØ±Ø¨": "AUTO", "Ø¥Ø¹Ù…Ø§Ø± Ù…ØµØ±": "EMFD", "Ù…ÙŠÙ†Ø§ Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± Ø§Ù„Ø³ÙŠØ§Ø­ÙŠ ÙˆØ§Ù„Ø¹Ù‚Ø§Ø±ÙŠ": "MENA",
    "Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø®Ø²Ù ÙˆØ§Ù„ØµÙŠÙ†ÙŠ": "PRCL", "Ø¬Ù†ÙˆØ¨ Ø§Ù„ÙˆØ§Ø¯Ù‰ Ù„Ù„Ø£Ø³Ù…Ù†Øª": "SVCE",
    "Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ù„Ù„Ù…Ø­Ø§ØµÙŠÙ„ Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠØ©": "IFAP", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„Ø®Ø²Ù Ø³ÙŠØ±Ø§Ù…ÙŠÙƒØ§": "CERA",
    "Ø§Ù„Ø¹Ø² Ù„Ù„Ø³ÙŠØ±Ø§Ù…ÙŠÙƒ ÙˆØ§Ù„Ø¨ÙˆØ±Ø³Ù„ÙŠÙ†": "ECAP", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ø­Ù„ÙŠØ¬ Ø§Ù„Ø£Ù‚Ø·Ø§Ù†": "ACGC",
    "Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¹Ø§Ù…Ø± Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©": "AMER", "Ø§Ù„Ù†ØµØ± Ù„Ù„Ù…Ù„Ø§Ø¨Ø³ ÙˆØ§Ù„Ù…Ù†Ø³ÙˆØ¬Ø§Øª": "KABO",
    "Ø§Ù„Ù…Ø·ÙˆØ±ÙˆÙ† Ø§Ù„Ø¹Ø±Ø¨ Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©": "ARAB", "Ø·Ø§Ù‚Ø© Ø¹Ø±Ø¨ÙŠØ© Ø´.Ù….Ù…": "TAQA", "Ø§Ù„Ø¹Ø¨ÙˆØ§Øª Ø§Ù„Ø·Ø¨ÙŠØ©": "MEPA",
    "Ø§Ù„Ù…ØµØ±Ù Ø§Ù„Ù…ØªØ­Ø¯": "UBEE", "Ø§Ù„Ø¹Ø¨ÙˆØ± Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ": "OBRI",
    "Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠ": "RREI", "Ù…ØµØ±Ù Ø£Ø¨Ùˆ Ø¸Ø¨ÙŠ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ - Ù…ØµØ±": "ADIB",
    "Ù†Ù‡Ø± Ø§Ù„Ø®ÙŠØ± Ù„Ù„ØªÙ†Ù…ÙŠØ©": "KRDI", "Ù…Ù…ÙÙŠØ³ Ù„Ù„Ø£Ø¯ÙˆÙŠØ©": "MPCI", "Ù…ØµØ± Ù„Ù„Ø£Ù„ÙˆÙ…Ù†ÙŠÙˆÙ…": "EGAL",
    "Ù…ØµØ± Ù„Ù„Ø£Ø³Ù…Ù†Øª": "MCQE", "Ù…ØµØ± Ø§Ù„ÙˆØ·Ù†ÙŠØ© Ù„Ù„ØµÙ„Ø¨": "ATQA", "Ù…ØµØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø§Ø³ÙƒØ§Ù†": "HELI",
    "Ù…Ø¯ÙŠÙ†Ø© Ù†ØµØ± Ù„Ù„Ø§Ø³ÙƒØ§Ù†": "MASR", "Ù…Ø§ÙƒØ±Ùˆ Ø¬Ø±ÙˆØ¨": "MCRO", "Ù„ÙŠØ³ÙŠÙƒÙˆ Ù…ØµØ±": "LCSW",
    "ÙƒÙˆÙ†ØªÙƒØª Ø§Ù„Ù…Ø§Ù„ÙŠØ©": "CNFN", "ÙØ§Ù„Ù…ÙˆØ± Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©": "VLMRA", "ØºØ§Ø² Ù…ØµØ±": "EGAS",
    "Ø¹Ø¨ÙˆØ± Ù„Ø§Ù†Ø¯": "OLFI", "Ù…Ø³ØªØ´ÙÙ‰ ÙƒÙ„ÙŠÙˆØ¨Ø§ØªØ±Ø§": "CLHO", "Ø§Ù„Ù‚Ù„Ø¹Ø© Ù„Ù„Ø§Ø³ØªØ´Ø§Ø±Ø§Øª": "CCAP",
    "Ø²Ù‡Ø±Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ø¯ÙŠ": "ZMID", "Ø±Ø§ÙŠØ© Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©": "RAYA", "Ø¯Ø§ÙŠØ³ Ù„Ù„Ù…Ù„Ø§Ø¨Ø³": "DSCW",
    "Ø¬Ù‡ÙŠÙ†Ø© Ù„Ù„ØµÙ†Ø§Ø¹Ø§Øª Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ©": "JUFO", "Ø¨ÙŠ Ø¥Ù†ÙØ³ØªÙ…Ù†ØªØ³": "BINV", "ÙƒØ±ÙŠØ¯ÙŠ Ø£Ø¬Ø±ÙŠÙƒÙˆÙ„": "CIEB",
    "Ø¨Ù†Ùƒ Ø§Ù„ØªØ¹Ù…ÙŠØ± ÙˆØ§Ù„Ø¥Ø³ÙƒØ§Ù†": "HDBK", "Ø¨Ù„ØªÙˆÙ† Ø§Ù„Ù…Ø§Ù„ÙŠØ©": "BTFH", "Ø¨Ø§ÙŠÙˆÙ†ÙŠØ±Ø² Ø¨Ø±ÙˆØ¨Ø±ØªÙŠØ²": "PRDC",
    "Ø§ÙŠ ÙØ§ÙŠÙ†Ø§Ù†Ø³": "EFIH", "Ø§Ù….Ø§Ù… Ø¬Ø±ÙˆØ¨": "MTIE", "Ø§Ù„Ù†Ø³Ø§Ø¬ÙˆÙ† Ø§Ù„Ø´Ø±Ù‚ÙŠÙˆÙ†": "ORWE",
    "Ø§Ù„Ù…Ù†ØµÙˆØ±Ø© Ù„Ù„Ø¯ÙˆØ§Ø¬Ù†": "MPCO", "Ø§Ù„Ù…Ù„ØªÙ‚Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ": "AMIA", "Ø§Ù„Ù…ØµØ±ÙŠØ© Ù„Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù…ÙŠ": "MPRC",
    "Ø§Ù„Ù…ØµØ±ÙŠØ© Ù„Ù„Ù…Ù†ØªØ¬Ø¹Ø§Øª": "EGTS", "Ø§Ù„Ù…ØµØ±ÙŠØ© Ù„Ù„Ø§ØªØµØ§Ù„Ø§Øª": "ETEL", "Ø§Ù„Ù…ØµØ±ÙŠØ© Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù†Ù‚Ù„": "ETRS",
    "Ø§Ù„Ù…ØµØ±ÙŠØ© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ù„Ù„ØµÙ†Ø§Ø¹Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ø¦ÙŠØ©": "PHAR"
}

# --- Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ---
STOCK_KEYWORDS = list(TICKER_MAP.keys()) + [
    "Ø³Ù‡Ù…", "Ø£Ø³Ù‡Ù…", "Ø¨ÙˆØ±ØµØ©", "Ø§Ø±Ø¨Ø§Ø­", "Ø£Ø±Ø¨Ø§Ø­", "Ø®Ø³Ø§Ø¦Ø±", "Ù†ØªØ§Ø¦Ø¬ Ø£Ø¹Ù…Ø§Ù„",
    "Ø²ÙŠØ§Ø¯Ø© Ø±Ø£Ø³ Ù…Ø§Ù„", "ØªÙˆØ²ÙŠØ¹ ÙƒÙˆØ¨ÙˆÙ†", "Ø§Ø³ØªØ­ÙˆØ§Ø°", "Ø§Ù†Ø¯Ù…Ø§Ø¬", "Ø§ÙƒØªØªØ§Ø¨",
    "Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ø§Ù„ÙŠØ©", "Ù…Ø¬Ù„Ø³ Ø¥Ø¯Ø§Ø±Ø©", "Ø¥ÙØµØ§Ø­", "ØªØ¯Ø§ÙˆÙ„", "Ø§Ù„Ø¨ÙˆØ±ØµØ© Ø§Ù„Ù…ØµØ±ÙŠØ©",
    "EGX", "ÙƒÙˆØ¨ÙˆÙ†", "Ø¬Ù…Ø¹ÙŠØ© Ø¹Ù…ÙˆÙ…ÙŠØ©", "Ù‡ÙŠØ¦Ø© Ø§Ù„Ø±Ù‚Ø§Ø¨Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ©", "Ù…ÙˆØ§Ø²Ù†Ø©"
]

# --- Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
FAIR_VALUES_FILE = "fair_values.json"
SENT_NEWS_DB_FILE = "sent_news_db.json"
HOURLY_SUMMARY_FILE = "hourly_news.json"

FAIR_VALUES_DB = {}

# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
def load_fair_values():
    global FAIR_VALUES_DB
    if os.path.exists(FAIR_VALUES_FILE):
        try:
            with open(FAIR_VALUES_FILE, 'r', encoding='utf-8') as f:
                FAIR_VALUES_DB = json.load(f)
                print(f"âœ… Loaded {len(FAIR_VALUES_DB)} fair value entries.")
        except Exception as e:
            print(f"âš ï¸ Error loading fair_values.json: {e}")
    else:
        print("âš ï¸ fair_values.json not found.")

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Gemini ---
client = None
selected_model_name = None
if GEMINI_API_KEY:
    try:
        client = genai.Client(api_key=GEMINI_API_KEY)
        selected_model_name = "gemini-2.0-flash-exp"
        print(f"âœ… Gemini Client initialized: {selected_model_name}")
    except Exception as e:
        print(f"âš ï¸ Gemini initialization failed: {e}")

# --- Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ---
RSS_FEEDS = [
    "https://www.arabfinance.com/ar/rss/rssbycat/2",
    "https://www.arabfinance.com/ar/rss/rssbycat/3",
    "http://feeds.mubasher.info/ar/EGX/news",
]

# --- Ø¯ÙˆØ§Ù„ Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± ---
def is_similar(title1, title2, threshold=0.85):
    return SequenceMatcher(None, title1.lower(), title2.lower()).ratio() >= threshold

def generate_news_hash(title, link):
    return hashlib.md5(f"{title.strip()}_{link.strip()}".encode('utf-8')).hexdigest()

# --- Ø¥Ø¯Ø§Ø±Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
def load_sent_news_db():
    if os.path.exists(SENT_NEWS_DB_FILE):
        try:
            with open(SENT_NEWS_DB_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸ Error loading DB: {e}")
            return {}
    return {}

def save_sent_news_db(db):
    try:
        # Ø§Ø­ØªÙØ¸ Ø¨Ø¢Ø®Ø± 1000 Ø®Ø¨Ø± ÙÙ‚Ø·
        keys_to_keep = list(db.keys())[-1000:]
        trimmed_db = {k: db[k] for k in keys_to_keep}
        with open(SENT_NEWS_DB_FILE, 'w', encoding='utf-8') as f:
            json.dump(trimmed_db, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ Error saving DB: {e}")

def load_hourly_news():
    if os.path.exists(HOURLY_SUMMARY_FILE):
        try:
            with open(HOURLY_SUMMARY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    return []

def save_hourly_news(news_list):
    try:
        with open(HOURLY_SUMMARY_FILE, 'w', encoding='utf-8') as f:
            json.dump(news_list, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ Error saving hourly news: {e}")

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ---
def find_tickers(text):
    found_tickers = set()
    text_lower = text.lower()
    for company, ticker in TICKER_MAP.items():
        if company.lower() in text_lower:
            found_tickers.add(ticker)
    return list(found_tickers)

def get_fair_value_data(tickers):
    data = {}
    for ticker in tickers:
        if ticker in FAIR_VALUES_DB:
            data[ticker] = FAIR_VALUES_DB[ticker]
    return data

async def analyze_news_with_gemini(title, description, fair_value_data):
    if not client or not selected_model_name:
        return {
            'summary': ['ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¨Ø± ØºÙŠØ± Ù…ØªØ§Ø­ Ø­Ø§Ù„ÙŠØ§Ù‹', 'ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹', 'ØªØ­Ù„ÙŠÙ„ ÙŠØ¯ÙˆÙŠ Ù…Ø·Ù„ÙˆØ¨'],
            'confidence': '5',
            'decision': 'Ø§Ù†ØªØ¸Ø§Ø± | Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„'
        }

    # ØªÙ†Ø³ÙŠÙ‚ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ø§Ø¯Ù„Ø©
    fv_text = "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù‚ÙŠÙ…Ø© Ø¹Ø§Ø¯Ù„Ø©"
    if fair_value_data:
        fv_lines = []
        for ticker, data in fair_value_data.items():
            company = data.get('company_names', [ticker])[0]
            fv = data.get('fair_value', 'N/A')
            upside = data.get('upside_percent', 0)
            fv_lines.append(f"- {company} ({ticker}): Ù‚ÙŠÙ…Ø© Ø¹Ø§Ø¯Ù„Ø© {fv} Ø¬.Ù…ØŒ ÙØ±ØµØ© ØµØ¹ÙˆØ¯ {upside:.1f}%")
        fv_text = '\n'.join(fv_lines)

    prompt = f"""Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø§Ù„ÙŠ Ù…Ø­ØªØ±Ù. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± Ø¨Ø´ÙƒÙ„ Ø³Ø±ÙŠØ¹ ÙˆÙ…Ø¨Ø§Ø´Ø±:

**Ø§Ù„Ø®Ø¨Ø±:** {title}
**Ø§Ù„ØªÙØ§ØµÙŠÙ„:** {description[:200] if description else 'Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙØ§ØµÙŠÙ„'}

**Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ø§Ø¯Ù„Ø©:**
{fv_text}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ (Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø§Ù„Ø¶Ø¨Ø·):**

Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: [ØªØ£Ø«ÙŠØ± Ø§Ù„Ø®Ø¨Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù‡Ù… ÙÙŠ Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©]
Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: [Ø±Ù‚Ù… Ø£Ùˆ Ù†Ø³Ø¨Ø© Ù…ØªÙˆÙ‚Ø¹Ø© Ù„Ù„ØªØ£Ø«ÙŠØ±]
Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©: [Ø§Ù„ØªÙˆØµÙŠØ©: Ø¥ÙŠØ¬Ø§Ø¨ÙŠ/Ø³Ù„Ø¨ÙŠ/Ù…Ø­Ø§ÙŠØ¯]
Ø§Ù„Ø«Ù‚Ø©: [Ø±Ù‚Ù… Ù…Ù† 1-10]
Ø§Ù„Ù‚Ø±Ø§Ø±: [Ø´Ø±Ø§Ø¡/Ø¨ÙŠØ¹/Ø§Ø­ØªÙØ§Ø¸] | Ø§Ù„Ù‡Ø¯Ù: [Ø±Ù‚Ù… Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù]

Ù…Ø«Ø§Ù„:
Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø§Ù„Ø´Ø±Ø§ÙƒØ© Ø³ØªØ¹Ø²Ø² Ù…Ø­ÙØ¸Ø© Ø§Ù„Ø¶ÙŠØ§ÙØ© ÙˆØªØ²ÙŠØ¯ Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª
Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Ù†Ù…Ùˆ Ù…ØªÙˆÙ‚Ø¹ 15-20% ÙÙŠ Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø¶ÙŠØ§ÙØ©
Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©: Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¯Ù‰ Ø§Ù„Ù…ØªÙˆØ³Ø·
Ø§Ù„Ø«Ù‚Ø©: 7
Ø§Ù„Ù‚Ø±Ø§Ø±: Ø´Ø±Ø§Ø¡ | Ø§Ù„Ù‡Ø¯Ù: 4.20
"""

    try:
        response = await asyncio.to_thread(
            client.models.generate_content,
            model=selected_model_name,
            contents=prompt
        )
        
        text = response.text.strip()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        point1_match = re.search(r'Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰:\s*(.+)', text)
        point2_match = re.search(r'Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©:\s*(.+)', text)
        point3_match = re.search(r'Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©:\s*(.+)', text)
        confidence_match = re.search(r'Ø§Ù„Ø«Ù‚Ø©:\s*(\d+)', text)
        decision_match = re.search(r'Ø§Ù„Ù‚Ø±Ø§Ø±:\s*(.+)', text)
        
        return {
            'summary': [
                point1_match.group(1).strip() if point1_match else 'ØªØ­Ù„ÙŠÙ„ Ù‚ÙŠØ¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©',
                point2_match.group(1).strip() if point2_match else 'ØªØ­Ù„ÙŠÙ„ Ù‚ÙŠØ¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©',
                point3_match.group(1).strip() if point3_match else 'ØªØ­Ù„ÙŠÙ„ Ù‚ÙŠØ¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©'
            ],
            'confidence': confidence_match.group(1) if confidence_match else '5',
            'decision': decision_match.group(1).strip() if decision_match else 'Ø§Ù†ØªØ¸Ø§Ø± | ØªØ­Ù„ÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠ'
        }
    except Exception as e:
        print(f"âš ï¸ Gemini analysis error: {e}")
        return {
            'summary': ['Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„', 'ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹', 'ØªØ­Ù„ÙŠÙ„ ÙŠØ¯ÙˆÙŠ Ù…Ø·Ù„ÙˆØ¨'],
            'confidence': '3',
            'decision': 'Ø§Ù†ØªØ¸Ø§Ø± | Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ'
        }

def is_stock_related(title, description):
    content = (title + ' ' + description).lower()
    return any(keyword.lower() in content for keyword in STOCK_KEYWORDS)

async def process_and_send(bot, title, description, link, sent_db, hourly_news):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø®Ø¨Ø± ÙÙˆØ±Ø§Ù‹"""
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§Ù„Ø£Ø³Ù‡Ù…
    if not is_stock_related(title, description):
        return False, "Not stock related"

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø± - Hash
    news_hash = generate_news_hash(title, link)
    if news_hash in sent_db:
        return False, "Duplicate hash"

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø± - Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    for existing_hash, existing_data in sent_db.items():
        if is_similar(title, existing_data.get('title', '')):
            return False, "Similar title"

    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ù…ÙˆØ² Ø§Ù„Ø£Ø³Ù‡Ù…
    tickers = find_tickers(title + ' ' + description)
    if not tickers:
        return False, "No tickers found"

    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ø§Ø¯Ù„Ø©
    fair_value_data = get_fair_value_data(tickers)
    if not fair_value_data:
        return False, "No fair value data"

    print(f"ğŸ“° Processing: {title[:50]}...")

    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¨Ø±
    analysis = await analyze_news_with_gemini(title, description, fair_value_data)

    # Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ù„ÙƒÙ„ Ø³Ù‡Ù…
    for ticker in tickers:
        if ticker not in fair_value_data:
            continue
            
        data = fair_value_data[ticker]
        company_name = data.get('company_names', [ticker])[0]
        
        curr_price = data.get('current_price')
        current_price_str = f"{curr_price:.2f}" if curr_price else "N/A"
        
        fv = data.get('fair_value')
        fv_str = f"{fv:.2f}" if fv else "N/A"
        
        upside_percent = data.get('upside_percent', 0)
        upside_icon = "ğŸ“ˆ" if upside_percent > 0 else ("ğŸ“‰" if upside_percent < 0 else "â†”ï¸")
        upside_str = f"{abs(upside_percent):.1f}%"

        message = (
            f"ğŸ›ï¸ <b>ØªØ­Ù„ÙŠÙ„ Ø³Ù‡Ù…: {company_name} (#{ticker})</b>\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ“Œ <b>Ø§Ù„Ø®Ø¨Ø±:</b> {title}\n\n"
            f"ğŸ“Š <b>Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©:</b>\n"
            f"  â€¢ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ: {current_price_str} Ø¬.Ù…\n"
            f"  â€¢ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ø§Ø¯Ù„Ø©: {fv_str} Ø¬.Ù…\n"
            f"  â€¢ ÙØ±ØµØ© Ø§Ù„ØµØ¹ÙˆØ¯: {upside_icon} {upside_str}\n\n"
            f"ğŸ’¡ <b>Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹:</b>\n"
            f"  â€¢ {analysis['summary'][0]}\n"
            f"  â€¢ {analysis['summary'][1]}\n"
            f"  â€¢ {analysis['summary'][2]}\n\n"
            f"ğŸ¯ <b>ØªÙˆØµÙŠØ© Ø§Ù„Ù…Ø­Ù„Ù„ (Ø«Ù‚Ø© {analysis['confidence']}/10):</b>\n"
            f"  {analysis['decision']}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"<a href=\"{link}\">ğŸ“° Ø§Ù„Ù…ØµØ¯Ø±</a> | â° {datetime.now().strftime('%H:%M')}"
        )

        try:
            await bot.send_message(
                chat_id=CHANNEL_ID,
                text=message,
                parse_mode=ParseMode.HTML,
                disable_web_page_preview=True
            )
            
            # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            sent_db[news_hash] = {
                'title': title,
                'link': link,
                'ticker': ticker,
                'timestamp': datetime.now().isoformat()
            }
            
            # Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø§Ø¹ÙŠ
            hourly_news.append({
                'title': title,
                'ticker': ticker,
                'company': company_name,
                'timestamp': datetime.now().isoformat(),
                'analysis': analysis['decision']
            })
            
            print(f"âœ… Sent: {ticker}")
            await asyncio.sleep(1.5)  # ØªØ£Ø®ÙŠØ± Ø¨Ø³ÙŠØ· Ø¨ÙŠÙ† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
            
        except Exception as e:
            print(f"âŒ Error sending {ticker}: {e}")

    return True, "Processed and sent"

async def send_hourly_summary(bot, hourly_news):
    """Ø¥Ø±Ø³Ø§Ù„ Ù…Ù„Ø®Øµ Ø³Ø§Ø¹ÙŠ Ù„Ù„Ø£Ø®Ø¨Ø§Ø±"""
    
    if not hourly_news:
        return
    
    # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø³Ù‡Ù…
    ticker_groups = {}
    for news in hourly_news:
        ticker = news['ticker']
        if ticker not in ticker_groups:
            ticker_groups[ticker] = []
        ticker_groups[ticker].append(news)
    
    summary_text = "ğŸ“Š <b>Ù…Ù„Ø®Øµ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø³Ø§Ø¹Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©</b>\n"
    summary_text += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    summary_text += f"â° {datetime.now().strftime('%d/%m/%Y - %H:%M')}\n\n"
    
    for ticker, news_list in ticker_groups.items():
        company = news_list[0]['company']
        summary_text += f"ğŸ¢ <b>{company} (#{ticker})</b>\n"
        for news in news_list:
            summary_text += f"  â€¢ {news['title'][:80]}...\n"
        summary_text += "\n"
    
    summary_text += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    summary_text += f"ğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {len(hourly_news)} Ø®Ø¨Ø±\n"
    summary_text += f"ğŸ›ï¸ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©: {len(ticker_groups)} Ø³Ù‡Ù…"
    
    try:
        await bot.send_message(
            chat_id=CHANNEL_ID,
            text=summary_text,
            parse_mode=ParseMode.HTML
        )
        print("âœ… Hourly summary sent")
    except Exception as e:
        print(f"âŒ Error sending summary: {e}")

async def fetch_rss_feeds(bot, sent_db, hourly_news):
    """Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† RSS"""
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    for url in RSS_FEEDS:
        try:
            response = requests.get(url, headers=headers, timeout=15)
            feed = feedparser.parse(response.content)
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø­Ø¯Ø« 20 Ø®Ø¨Ø± Ù…Ù† ÙƒÙ„ Ù…ØµØ¯Ø±
            for entry in feed.entries[:20]:
                await process_and_send(
                    bot,
                    entry.title,
                    entry.get('summary', ''),
                    entry.link,
                    sent_db,
                    hourly_news
                )
                await asyncio.sleep(0.5)  # ØªØ£Ø®ÙŠØ± ØµØºÙŠØ± Ø¨ÙŠÙ† Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
                
        except Exception as e:
            print(f"âš ï¸ Error fetching {url[:40]}: {e}")

async def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    
    if not all([TELEGRAM_TOKEN, CHANNEL_ID, GEMINI_API_KEY]):
        print("âŒ Missing environment variables!")
        return

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    load_fair_values()
    sent_db = load_sent_news_db()
    hourly_news = load_hourly_news()
    
    bot = Bot(token=TELEGRAM_TOKEN)
    
    print(f"\nğŸ¤– EGX News Bot v7.0 Started")
    print(f"ğŸ“Š Model: {selected_model_name or 'N/A'}")
    print(f"ğŸ“° Tracked: {len(sent_db)} news\n")
    
    last_summary_time = datetime.now()
    
    # Ø­Ù„Ù‚Ø© Ù…Ø³ØªÙ…Ø±Ø©
    while True:
        try:
            # Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
            await fetch_rss_feeds(bot, sent_db, hourly_news)
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø§Ø¹ÙŠ
            current_time = datetime.now()
            if (current_time - last_summary_time) >= timedelta(hours=1):
                await send_hourly_summary(bot, hourly_news)
                hourly_news = []  # Ù…Ø³Ø­ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ù„Ø®Øµ
                last_summary_time = current_time
            
            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            save_sent_news_db(sent_db)
            save_hourly_news(hourly_news)
            
            print(f"âœ… Cycle completed. Tracked: {len(sent_db)}, Hourly: {len(hourly_news)}")
            
            # Ø§Ù†ØªØ¸Ø§Ø± 3 Ø¯Ù‚Ø§Ø¦Ù‚ Ù‚Ø¨Ù„ Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
            await asyncio.sleep(180)
            
        except Exception as e:
            print(f"âŒ Error in main loop: {e}")
            await asyncio.sleep(60)  # Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ù‚ÙŠÙ‚Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø®Ø·Ø£

if __name__ == "__main__":
    asyncio.run(main())
